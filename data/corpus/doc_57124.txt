Реализация системы машинного обучения для синтеза изображений по текстовому описанию

Опубликована открытая реализация системы машинного обучения DALL-E 2, предложенной компанией OpenAI и позволяющей синтезировать реалистичные изображения и картины на основании текстового описания на естественном языке, а также применять команды на естественном языке для редактирования изображений (например, добавлять, удалять или перемещать объекты на изображении). Исходные модели DALL-E 2 от компании OpenAI не публикуются, но доступна статья с подробным описанием метода. На основе имеющегося описания независимыми исследователями подготовлена альтернативная реализация, написанная на языке Python, использующая фреймворк Pytorch и распространяемая под лицензией MIT. По сравнению с ранее опубликованной реализацией первого поколения DALL-E, новый вариант обеспечивает более точное соответствие изображения описанию, позволяет добиться большего фотореализма и даёт возможность формировать изображения в более высоких разрешениях. Система требует больших ресурсов для обучения модели, например, на обучение исходного варианта DALL-E 2 необходимо 100-200 тысяч часов вычислений на GPU, т.е. около 2-4 недель вычислений при наличии 256 GPU NVIDIA Tesla V100. Тем же автором также началась разработка расширенного варианта - DALLE2 Video, нацеленного на синтез видео по текстовому описанию. Отдельно можно отметить развиваемый Сбербанком проект ru-dalle, с открытой реализацией первого поколения DALL-E, адаптированной для распознавания описаний на русском языке.