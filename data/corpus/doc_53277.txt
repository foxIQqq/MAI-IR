MIT удалил коллекцию Tiny Images из-за выявления расистских и женоненавистнических терминов

Массачусетский технологический институт удалил набор данных Tiny Images, включающий аннотированную коллекцию из 80 миллионов небольших изображений с разрешением 32x32. Набор поддерживался группой, развивающей технологии компьютерного зрения, и использовался c 2008 года различными исследователями для тренировки и проверки распознавания объектов в системах машинного обучения. Поводом к удалению стало выявление использования расистских и женоненавистнических терминов в метках, характеризующих изображённые на картинках объекты, а также наличия образов, которые воспринимались как оскорбительные. Например, присутствовали изображения половых органов с жаргонными терминами, изображения некоторых женщин характеризовались как "шлюхи", применялись недопустимые в современном обществе термины для чернокожих и азиатов. Однако в документе, на который ссылается MIT, названы и более серьёзные проблемы с такими коллекциями: технологии компьютерного зрения можно использовать для разработки систем распознавания лиц, для поиска представителей запрещённых почему-либо групп населения; нейросеть для генерации изображений может восстановить оригинал по анонимизированным данным. Причиной появления недопустимых слов было использование лексической базы данных английского языка WordNet, созданной в 1980-е годы в Принстонском университете: из неё были взяты существительные, по которым в интернете были найдены картинки, которые после этого были уменьшены. Претензии предъявлены не только к меткам картинок, но и к самим картинкам. Так как вручную проверить 80 млн мелких картинок не представляется возможным, было принято решение полностью закрыть доступ к БД. MIT также призвал других исследователей прекратить использование данной коллекции и удалить её копии. Аналогичные проблемы наблюдаются и в крупнейшей аннотированной базе изображений ImageNet, в которой также используются привязки из WordNet.