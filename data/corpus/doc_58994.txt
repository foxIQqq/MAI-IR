Проект RedPajama развивает открытый набор данных для систем искусственного интеллекта

Представлен совместный проект RedPajama, нацеленный на создание открытых моделей машинного обучения и сопутствующих исходных данных для тренировки, которые могут использоваться для создания интеллектуальных помощников, конкурирующих c коммерческими продуктами, такими как ChatGPT. Предполагается, что наличие открытых исходных данных и крупных языковых моделей избавит от ограничений независимые команды, занимающихся исследованиями в области машинного обучения, и упростит создание специализированных диалоговых систем. К работе над проектом присоединились таки организации и сообщества, как Together, Ontocord.ai, ETH DS3Lab, Stanford CRFM, Hazy Research и MILA Québec AI Institute. Первым шагом стала публикация набора данных RedPajama-Data-1T для обучения диалоговых моделей, насчитывающего 1.2 триллиона токенов. Набор RedPajama воспроизводит данные из общедоступных источников, использованные компанией Facebook для создания своей модели LLaMA (насчитывает 1.25 триллионов токенов), но поставляется под открытой лицензией, не ограничивающей область использования (данные и модели LLaMA поставлялись только исследователям по специальному запросу для некоммерческого использования). Размер подготовленного для загрузки набора RedPajama-Data-1T составляет 2.67 ТБ и включает информацию из проиндексированных проектом Common Crawl web-страниц, архивов Wikipedia, исходного кода из GitHub, общедоступных книг из библиотеки Gutenberg, научных статей из архива ArXiv и обсуждений со Stack Overflow и других сайтов Stack Exchange. Готовые модели, обученные на основе подготовленного набора данных и оптимизированные с использованием готовых примеров диалогов в форме инструкция-выполнение от проектов Alpaca и OpenChatKit, планируют сформировать в ближайшие несколько недель. Из похожих инициатив по созданию языковых моделей упоминаются частично открытые проекты LLaMA, Alpaca, Vicuna, and Koala, а также полностью открытые инициативы Pythia, OpenChatKit, Open Assistant и Dolly. Дополнительно можно отметить несколько новых проектов, связанных с машинным обучением: MiniGPT-4 - расширяет традиционные диалоговые чатботы возможностями, учитывающими визуальную информацию, что позволяет анализировать изображения и учитывать рукописный текст в процессе взаимодействия с системой (например, можно спросить, что за объект изображён на картинке, попросить бота написать рассказ по мотивам изображённого на фотографии или на основе схематичного наброска попросить создать web-сайт). Реализация MiniGPT-4 написана на языке Python и распространяется под лицензией BSD. Компания Facebook опубликовала инструментарий и самообучающуюся (SSL, Self-Supervised Learning, не использует при обучении подготовленные человеком метки и аннотации) модель машинного зрения DINOv2, подходящую для решения задач обобщённой визуальной обработки данных (классификация изображений, извлечение сведений об объектах на изображениях, понимание происходящего на видео) и манипуляций на пиксельном уровне (прогнозирование глубины, сегментация). Модель натренирована на коллекции из 142 млн изображений. Реализация написана на языке Python и распространяется под лицензией Creative Commons Attribution-NonCommercial 4.0, допускающей использования в некоммерческих целях. GPT4All - инструментарий для быстрого запуска обособленных чатботов на своём оборудовании (не обращаются к внешним сервисам и используют для выполнения CPU с поддержкой AVX2). Поддерживается подключение больших языковых моделей на основе GPT-J и LLaMa. Код написан на языке Python и распространяется под лицензией MIT.