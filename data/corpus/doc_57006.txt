Выпуск системы управления контейнерами LXD 5.0

Компания Canonical опубликовала релиз менеджера контейнеров LXD 5.0 и виртуальной ФС LXCFS 5.0. Код LXD написан на языке Go и распространяется под лицензией Apache 2.0. Ветка 5.0 отнесена к выпускам с длительной поддержкой - обновления будут формироваться до июня 2027 года. В качестве runtime для запуска как контейнеров используется инструментарий LXC, в состав которого входит библиотека liblxc, набор утилит (lxc-create, lxc-start, lxc-stop, lxc-ls и т.п.), шаблоны для построения контейнеров и набор биндингов для различных языков программирования. Изоляция осуществляется при помощи штатных механизмов ядра Linux. Для изоляции процессов, сетевого стека ipc, uts, идентификаторов пользователей и точек монтирования используется механизм пространств имён (namespaces). Для ограничения ресурсов применяются cgroups. Для понижения привилегий и ограничения доступа задействованы такие возможности ядра, как профили Apparmor и SELinux, политики Seccomp, Chroots (pivot_root) и capabilities. Помимо LXC в LXD также применяются компоненты от проектов CRIU и QEMU. Если LXC является низкоуровневым инструментарием для манипуляции на уровне отдельных контейнеров, то LXD предоставляет средства для централизованного управления контейнерами, развёрнутыми в кластере из нескольких серверов. LXD реализован в виде фонового процесса, принимающего запросы по сети через REST API и поддерживающего различные бэкенды хранилищ (дерево директорий, ZFS, Btrfs, LVM), снапшоты со срезом состояния, live-миграцию работающих контейнеров с одной машины на другую и средства для хранения образов контейнеров. LXCFS применяется для симуляции в контейнерах псевдо-ФС /proc и /sys, а виртуализированного представления cgroupfs для придания контейнерам вида обычной независимой системы. Ключевые улучшения: Возможность горячего подключения и отключения дисков и USB-устройств. В виртуальной машине новый диск определяется через появление нового устройства на шине SCSI, а USB-устройство - генерацией события USB hotplug. Предоставлена возможность запуска LXD даже в условиях невозможности поднятия сетевого соединения, например, из-за отсутствия необходимого сетевого устройства. Вместо вывода ошибки при запуске LXD теперь запускает максимально возможное в текущих условиях число окружений, а остальные окружения запускаются после того как будет налажено сетевое соединение. Добавлена новая роль членов кластера - ovn-chassis, предназначенная для кластеров, использующих OVN (Open Virtual Network) для сетевого взаимодействия (через присвоение роли ovn-chassis можно выделить серверы для выполнения функций маршрутизаторов OVN). Предложен оптимизированный режим обновления содержимого разделов хранилища. В прошлых выпусках обновление сводилось к тому, что вначале экземпляр контейнера или раздел копировался, например, через применение функциональности send/receive в zfs или btrfs, после чего созданная копия синхронизировалась через запуск программы rsync. Для повышения эффективности обновления виртуальных машин в новом выпуске задействована продвинутая логика миграции, при которой в случае, если исходный и целевой сервер используют один пул хранения, вместо rsynс автоматически применяются снапшоты и операции send/receive. Переработана логика идентификации окружений в cloud-init: вместо имён окружений в качестве instance-id теперь используется UUID. Добавлена поддержка перехвата системного вызова sched_setscheduler, позволяющая непривилегированным контейнерам изменять приоритеты процессов. Реализована опция lvm.thinpool_metadata_size, управляющая размером метаданных в thinpool. Переработан формат файла с сетевой информацией для lxc. Добавлена поддержка данных о связывании интерфейсов, сетевых мостах, VLAN и OVN-сети. Повышены требования к минимальным версиям компонентов: ядро Linux 5.4, Go 1.18, LXC 4.0.x и QEMU 6.0. В LXCFS 5 добавлена поддержка унифицированной иерархии cgroup (cgroup2), реализованы /proc/slabinfo и /sys/devices/system/cpu, для сборки задействован инструментарий meson.