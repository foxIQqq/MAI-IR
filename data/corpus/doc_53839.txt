Facebook развивает TransCoder для перевода кода с одного языка программирования на другой

Инженеры из Facebook опубликовали транскомпилятор TransCoder, использующий методы машинного обучения для преобразования исходных текстов с одного высокоуровневого языка программирования на другой. В настоящее время предоставлена поддержка трансляции кода между языками Java, C++ и Python. Например, TransCoder позволяет преобразовать исходные тексты на Java в код на Python, а код на Python в исходные тексты на Java. Наработки проекта реализуют на практике теоретические изыскания по созданию нейронной сети для эффективной автоматической транскомпиляции кода и распространяются под лицензией Creative Commons Attribution-NonCommercial 4.0, разрешающей применение только для некоммерческих целей. Реализация системы машинного обучения построена на базе Pytorch. Для загрузки предложены две готовые модели: первая для трансляции C++ в Java, Java в C++ и Java в Python, а вторая для трансляции C++ в Python, Python в C++ и Python в Java. Для обучения моделей использовалась исходные тексты проектов, размещённых на GitHub. При желании модели трансляции могут быть созданы и для других языков программирования. Для проверки качества трансляции подготовлена коллекция unit-тестов, а также тестовый набор, включающий 852 параллельных функции. Утверждается, что по точности преобразования TransCoder значительно превосходит коммерческие трансляторы, использующие методы на основе правил преобразования, и в процессе работы позволяет обойтись без экспертной оценки знатоков исходного и целевого языка. Большую часть ошибок, возникающий при работе модели, удаётся устранить через добавление простых ограничений в декодировщик, позволяющих гарантировать, что генерируемые функции будут синтаксически корректны. Исследователями использована архитектура нейронной сети "Transformer" для моделирования последовательностей, в которой рекуррентность заменена "вниманием" (seq2seq model with attention), что позволяет избавиться от некоторых зависимостей в вычислительном графе и распараллелить то, что раньше не поддавалось распараллеливанию. Для всех поддерживаемых языков применяется единая общая модель, при тренировке которой используются три принципа - инициализация, моделирование языка и обратный перевод.