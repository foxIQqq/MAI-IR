Представлена новая открытая система синтеза изображений Stable Diffusion

Открыты наработки, связанные с системой машинного обучения Stable Diffusion, синтезирующей изображения на основе текстового описания на естественном языке. Проект развивается совместными усилиями исследователями из компаний Stability AI и Runway, сообществ Eleuther AI и LAION, а также группы CompVis lab (лаборатория исследований в области машинного зрения и машинного обучения при Мюнхенском университете). По возможностям и уровню качества результата Stable Diffusion напоминает проект DALL-E 2, но развивается как открытый и общедоступный. Реализация Stable Diffusion написана на языке Python и распространяется под лицензией MIT. Готовые модели в настоящий момент предоставляются по отдельному запросу образовательным учреждениям и независимым исследователям, но разработчики обещают открыть их для всех желающих после завершения тестирования и готовности первого релиза. Для обучения системы использовался кластер из 4000 GPU NVIDIA A100 Ezra-1 и коллекция LAION-5B, включающая 5.85 миллиардов изображений с текстовыми описаниями. Компоненты для генерации изображения отмечаются как достаточно легковесные для работы на пользовательских системах, например, для синтеза изображений с разрешением 512x512 достаточно наличия в системе GPU с 10GB видеопамяти. Кроме синтеза изображений по текстовому описанию предлагается вариант для модификации изображений, который может с использованием уточняющих текстовых подсказок генерировать картины по схематичным наброскам, редактировать и изменять изображения или восстанавливать утраченные детали при увеличении масштаба. В разработке также находится вариант Stable Diffusion для редактирования видео на основе текстовых команд на естественном языке.