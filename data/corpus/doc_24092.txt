В ZFS появилась поддержка исключения дубликатов

Jeff Bonwick, создатель файловой системы ZFS, сообщил в своем блоге о реализации интересного новшества - системы автоматического распознавания и объединения дубликатов. Технология поддерживает работу на уровне блоков данных, что по оценке разработчиков Sun является более универсальным и менее ресурсоемким вариантом, по сравнению с вычислением дубликатов на уровне файлов или произвольных наборов байт. Для каждого блока вычисляется контрольная сумма SHA256, если данная контрольная сумма уже присутствует в хэше, производится создание ссылки на уже имеющийся набор данных. Иными словами, если в нескольких файлах присутствуют аналогичные блоки данных, то они будут сохранены на физический носитель только один раз. Представленная возможность позволит существенно уменьшить потребление дискового пространства и увеличить производительность - вместо копирования блоков будет лишь изменена запись в соответствующей таблице. Наиболее заметный эффект от технологии исключения дубликатов можно наблюдать при организации резервного копирования, в больших репозиториях исходных текстов и в системах виртуализации с большим набором типовых гостевых окружений. В таких системах может быть достигнута экономия дискового пространства в разы. Включение новшества производится командой "zfs set dedup=on имя_пула" или "zfs set dedup=on имя_пула/отдельная_директория". Для систем, на которых не достаточно проверки по хэшу SHA256, предусмотрен режим повышенной надежности, при котором производится дополнительное полное сравнение блоков данных при совпадении хэша. Данный режим включается через "zfs set dedup=verify имя_пула". Вместо SHA256 в сочетании с режимом verify можно использовать менее надежный, но более быстрый метод вычисления контрольной суммы - fletcher4 ("zfs set dedup=fletcher4,verify имя_пула").