Hadoop установил новый мировой рекорд

Команда разработчиков системы распределенных вычислений Yahoo объявила о том, что используя Apache Hadoop, они смогли побить мировой рекорд в сортировке не специфичных (general purpose) данных. Новое значение рекорда — 1 терабайт за 62 секунды или петабайт за 16.25 часа. Измерения проводились на кластере Yahoo Hammer, который содержит приблизительно 3800 серверов, в каждом из которых по 2 четырехядерных процессора Xeon 2.5ГГц, 4 SATA диска, 16Гб ОЗУ, 1Гбит сетевая карта. В качестве ОС используется RHEL 5.1, а для обработки данных Sun Java JDK версий 1.6.0_05-b13 и 1.6.0_13-b03. Apache Hadoop — это открытая среда для проведения процессороемких распределенных вычислений. Ее использование позволяет приложениям получать доступ к массивам неструктурированной информации петабайтного объема. Проект начал развиваться в качестве открытой альтернативы Google File System (GFS) и проприетарной реализации алгоритма MapReduce. Hadoop — это единственный открытый алгоритм, когда-либо побеждавший в соревновании GraySort. Прошлогодний результат сортировки 1 терабайта данных, показанный также Hadoop на соревновании Terasort, равнялся 209 секундам.