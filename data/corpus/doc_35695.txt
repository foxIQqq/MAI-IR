Доступна открытая платформа для устройств естественного взаимодействия - OpenNI 2.0

Консорциум OpenNI после двух лет разработки представил открытую платформу OpenNI 2.0, в рамках которой подготовлен универсальный фреймворк для организации работы систем естественного взаимодействия с пользователем. Консорциум OpenNI основан компанией PrimeSense, технологии которой использованы Microsoft при создании устройства Kinect, при участии компаний Willow Garage и ASUS, с целью продвижения единого программного интерфейса для обеспечения совместимости и переносимости приложений, промежуточного ПО и устройств естественного взаимодействия. Код платформы распространяется под лицензией Apache 2.0. Для разработчиков приложений подготовлен OpenNI SDK, который включает библиотеки, документацию, драйверы для устройств-сенсоров, утилиты и дополнительные runtime-компоненты. Бинарные сборки доступны для Windows и Ubuntu. Под естественным взаимодействием понимается возможность управления приложениями через движения пользователя и голосовые команды. Кроме игровых приложений, в которых движения пользователя отражаются на течении игрового процесса, интерфейсы естественного взаимодействия также могут быть использованы для создания интуитивных форм управления бытовой электроникой. Например, условное движение руки может включить определённый бытовой прибор или переключить канал телевизора. При помощи OpenNI в приложениях можно реализовать такие возможности, как распознавание управляющих речевых команд, интерпретация определённых движений рукой в качестве управляющих команд, отслеживание и анализ движения тела. Из поддерживаемых сенсоров для приёма визуальной и аудио информации, отмечаются 3D-сенсоры, позволяющие определить расстояние до объекта с учётом глубины помещения, цветные и инфракрасные камеры, микрофоны. Для анализа содержимого сцены и осмысления происходящего на основе доступной визуальной и звуковой информации отдельно поставляется специальное промежуточное ПО, которое позволяет выполнять такие действия, как выявление позиции кисти руки, оценка положения тела (позиция суставов в пространстве и смещение центра масс), отслеживание перемещения тела, реконструкция 3D-сцены и распознавание объектов. На основании данных от анализатора положения кистей рук при помощи специального компонента могут быть выделены управляющие жесты и преобразованы в команды приложению. По сравнению с первой редакцией платформы OpenNI в новой версии проведена работа по обеспечению совместимости и переносимости между устройствами, приложениями и промежуточным ПО. Подготовлен SDK и переработан API для использования в приложениях. Расширено число поддерживаемых 3D-сенсоров. Добавлена поддержка устройств Kinect. Упрощено одновременное использование нескольких сенсоров. Функции Algorithms API перенесены на сторону промежуточных (middleware) библиотек. Добавлен API для событийно-ориентированного программирования. Реализована возможность трансляции данных о глубине пикселей в координаты цветовой карты.