Компания Mozilla представила систему синтеза речи LPCNet

Компания Mozilla развивает новую систему синтеза речи LPCNet, которая дополняет ранее запущенную инициативу по разработке системы распознавания речи. LPCNet обеспечивает более эффективный синтез речи благодаря комбинированию традиционных методов цифровой обработки сигналов (DSP) с механизмами синтеза на основе машинного обучения. Исходные тексты реализации LPCNet распространяются под лицензией BSD. Несмотря на то, что современные модели синтеза речи на основе нейронных сетей, такие как WaveNet, позволяют добиться превосходного качества синтеза, их реализация сильно усложнена и требует большой вычислительной мощности. Данная особенность затрудняет использование подобных систем для синтеза речи в режиме реального времени на таких устройствах, как телефоны. В качестве выхода в LPCNet предлагается использовать DSP для LPC-фильтрации (Linear Prediction) и моделирования вокального тракта с последующей обработкой полученных параметров в рекуррентной нейронной сети. Особенностью LPCNet является то, что вместо передачи в нейронную сеть только выбранных сэмплов, производится приблизительное прогнозирование следующего сэмпла, что позволяет заметно сократить размер нейронной сети и уменьшить необходимые для её работы ресурсы. Таким образом, с нейронной сети снимается работа по моделированию вокального тракта и остаётся только задача корректировки проблем при прогнозировании. Помимо синтеза речи LPCNet также может применяться и в других областях, требующих повышения качества голосового сигнала. Например, LPCNet подходит для создания технологий сжатия речи для передачи по низкоскоростным каналам связи (уже развивается соответствующий кодек), для устранения шумов, для изменения скорости воспроизведения речи, для фильтрации результата работы различных кодеков и для синтезирования недостающих фрагментов, утерянных из-за потери пакетов. Код реализации LPCNet написан на языке Си с использованием Keras, высокоуровневого фреймворка для построения нейронных сетей, который может работать поверх TensorFlow, CNTK и Theano. Для работы требуется GPU (достаточно GT1060, но для обучения модели рекомендуется использовать более мощный GPU с поддержкой CUDA и CUDNN, например GTX 1080 Ti). Для загрузки доступны уже готовые модели, натренированные на голосовых данных от лаборатории университета Макгилла. Систему можно обучить и на своих данных, для этого потребуется несколько часов аннотированных записей голоса (например, можно научить LPCNet синтезировать речь любым голосом).