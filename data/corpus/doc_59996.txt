Открыт код Jina Embedding, модели для векторного представления смысла текста

Компания Jina открыла под лицензией Apache 2.0 модель машинного обучения для векторного представления текста - jina-embeddings-v2. Модель позволяет преобразовать произвольный текст, включающий до 8192 знаков, в небольшую последовательность вещественных чисел, образующих вектор, сопоставленный с исходным текстом и воспроизводящий его семантику (смысл). Jina Embedding стала первой открытой моделью машинного обучения, обладающей характеристиками, не уступающими проприетарной модели векторизации текста от проекта OpenAI (text-embedding-ada-002), также способной обрабатывать тексты, насчитывающие до 8192 токенов. Расстояние между двумя сформированными векторами можно использовать для определения смысловой взаимосвязи исходных текстов. На практике сформированные векторы могут применяться для анализа похожести текстов, организации поиска близких по тематике материалов (ранжирование результатов по семантической близости), группировки текстов по смыслу, формирования рекомендаций (предложение списка похожих текстовых строк), выявления аномалий, определения плагиата и классификации тестов. В качестве примеров областей использования упоминается задействование модели для анализа юридических документов, для бизнес-аналитики, в медицинских исследованиях для обработки научных статей, в литературной критике, для разбора финансовых отчётов и для повышения качества обработки чат-ботами сложных вопросов. Для загрузки доступны два варианта модели jina-embeddings (базовая - 0.27 ГБ и сокращённая - 0.07 ГБ), обученные на 400 миллионах пар текстовых последовательностей на английском языке, охватывающих различные области знаний. При обучении использовались последовательности, размером 512 токенов, которые были экстраполированы до размера 8192 при помощи метода ALiBi (Attention with Linear Biases). Базовая модель включает в себя 137 млн параметров и рассчитана на использовании на стационарных системах с GPU. Сокращённая модель включает 33 млн. параметров, обеспечивает меньшую точность и нацелена на применение на мобильных устройствах и на системах с небольшим объёмом памяти. В ближайшее время также планируют опубликовать крупную модель, которая будет охватывать 435 млн параметров. В разработке также находится многоязычный вариант модели, который в настоящее время сосредоточен на поддержке немецкого и испанского языков. Отдельно подготовлен плагин для использования модели jina-embeddings через инструментарий LLM.