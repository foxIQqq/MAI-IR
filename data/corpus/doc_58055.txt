Судебное разбирательство против Microsoft и OpenAI, связанное с генератором кода GitHub Copilot

Мэтью Баттерик (Matthew Butterick), разрабатывающий открытые проекты для типографики, и юридическая компания Joseph Saveri Law Firm, инициировали судебное разбирательство (PDF) против производителей технологий, используемых в сервисе GitHub Copilot. Среди ответчиков Microsoft, GitHub и компании, курирующие проект OpenAI, подготовивший модель генерации кода OpenAI Codex, которая лежит в основе GitHub Copilot. В ходе разбирательства предпринята попытка привлечь суд к определению степени законности создания сервисов, подобных GitHub Copilot, и выяснению, нарушают ли такие сервисы права других разработчиков. Деятельность ответчиков сравнивается с созданием нового вида пиратства программного обеспечения, основанного на манипуляции существующим кодом при помощи методов машинного обучения и позволяющего извлекать выгоду за счёт работы других людей. Создание Copilot также рассматривается как введение в практику нового механизма монетизации труда разработчиков открытого ПО, несмотря то, что GitHub ранее обещал никогда этого не делать. Позиция истцов сводится к тому, что результат генерации кода системой машинного обучения, натренированной на публично доступных исходных текстах, нельзя трактовать как принципиально новую и самостоятельную работу, так как она является следствием обработки алгоритмами уже существующего кода. По мнению истцов Copilot лишь воспроизводит код, который имеет прямые отсылки к существующему коду в открытых репозиториях, и подобные манипуляции не подпадают под критерии добросовестного использования. Иными словами, синтез кода в GitHub Copilot рассматривается истцами как создание производной работы от существующего кода, распространяемого под определёнными лицензиями и имеющего конкретных авторов. В частности, при обучении системы Copilot используется код, распространяемый под открытыми лицензиями, в большинстве случаев требующими извещения об авторстве (атрибуция). При генерации результирующего кода данное требование не выполняется, что является явным нарушением большинства открытых лицензий, таких как GPL, MIT и Apache. Кроме того, в Copilot нарушаются собственные условия GitHub, касающиеся оказания услуг и обеспечения конфиденциальности, не соблюдаются требования закона DMCA, запрещающего удалять информацию об авторских правах, и закона CCPA (California Consumer Privacy Act), регулирующего обращение с персональными данными. В тексте иска приведён приблизительный расчёт ущерба, который нанесён сообществу в результате деятельности Copilot. В соответствии с 1202 статьёй Закона об авторском праве в цифровую эпоху (DMCA, Digital Millennium Copyright Act), минимальный размер ущерба составляет 2500 долларов за каждое нарушение. С учётом того, что сервис Copilot насчитывает 1.2 млн пользователей и при каждом использовании сервиса возникает три нарушения DMCA (атрибуция, копирайт и условия лицензии), минимальный размер общего ущерба оценён в 9 миллиардов долларов (1200000 * 3 * $2500). Правозащитная организация Software Freedom Conservancy (SFC), ранее выступавшая с критикой GitHub и Copilot, прокомментировала иск рекомендацией не отклоняться при защите интересов сообщества от одного из ранее сформулированных принципов - "ориентированное на сообщество правоприменение не должно уделять первостепенное внимание финансовой выгоде". По мнению SFC действия Copilot неприемлемы прежде всего тем, что подрывают механизм "копилефт", нацеленный на предоставление равных прав пользователям, разработчикам и потребителям. Многие из охваченных в Copilot проектов поставляются под копилефт-лицензиями, такими как GPL, требующими поставки под совместимой лицензией кода производных работ. В случае вставки предложенного Copilot существующего кода разработчики могут невольно нарушить лицензию на проект, из которого был заимствован данный код. Напомним, что летом GitHub запустил новый коммерческий сервис GitHub Copilot, натренированный на массиве исходных текстов, размещённых в публичных репозиториях GitHub, и способный генерировать типовые конструкции при написании кода. Сервис может формировать достаточно сложные и большие блоки кода, вплоть до готовых функций, которые могут повторять отрывки текста из существующих проектов. По данным GitHub система пытается воссоздать структуру кода, а не копирует сам код, тем не менее примерно в 1% случаев предлагаемая рекомендация может включать отрывки кода существующих проектов размером более 150 символов. Для предотвращения подстановки существующего кода в Copilot встроен специальный фильтр, проверяющий пересечения с размещёнными на GitHub проектами, но данный фильтр активируется на усмотрение пользователя. За два дня до подачи иска GitHub объявил о намерении реализовать в 2023 году функцию, позволяющую отслеживать связь генерируемых в Copilot фрагментов с существующим в репозиториях кодом. Разработчики смогут просмотреть список похожего кода, уже присутствующего в публичных репозиториях, а также отсортировать пересечения по лицензиям на код и времени внесения изменения.