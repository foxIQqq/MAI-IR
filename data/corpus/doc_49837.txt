Facebook опубликовал открытую систему распознавания речи Wav2letter++

Разработчики из лаборатории искусственного интеллекта Facebook AI Research представили первый выпуск новой системы распознавания речи Wav2letter++, построенной с использованием свёрточной нейронной сети. В отличие от опубликованного в январе начального прототипа, реализация wav2letter++ полностью переписана на языке C++ с использованием библиотек ArrayFire и Flashlight (первый прототип был в форме Torch-модуля на языке Lua). Код проекта распространяется под лицензией BSD. Доступны уже натренированные модели (1, 2, 3) для английского языка. Для распознавания в Wav2letter++ предложена новая архитектура, основанная на использовании акустической и языковой моделей, созданных при помощи системы машинного обучения на базе свёрточной нейронной сети (CNN). Система использует метод посимвольного предсказания на основе разбора необработанной формы сигнала без предварительного разделения фонем при проведении машинного обучения. После фазы посимвольного разбора для определения слов применяется внешняя языковая модель, выполненная также на основе свёрточной нейронной сети. Задействованные в проекте функции низкоуровневой обработки звука основаны на библиотеки Libsndfile, а для цифровой обработки сигналов при помощи дискретного преобразования Фурье применяется библиотека FFTW. Для обучения в проекте реализована техника автоматического сегментирования, которая позволяет обучить систему на основе записи звука и текстовой транскрипции, без дополнительных аннотаций. Для работы декодировщика требуется только список слов и языковая модель - весовые характеристики букв выделяются из акустической модели, без необходимости подключения словарей фонетической лексики. Для ускорения проведения обучения поддерживается задействование GPU (CUDA) и кластерных систем (OpenMPI и TorchMPI). Система демонстрирует хорошую производительность, которая позволяет по скорости конкурировать с решениями на базе рекуррентных нейронных сетей. По скорости обучения в некоторых ситуациях Wav2letter++ более чем в два раза опережает другие оптимизированные фреймворки распознавания речи на базе алгоритмов машинного обучения. Время обучения линейно масштабируется в зависимости от числа GPU. Скорость декодирования в Wav2letter++ на порядок опережает реализации OpenSeq2Seq и ESPNet при сопоставимом или меньшем уровне ошибок. На тестовом наборе LibriSpeech система демонстрирует уровень ошибок 4.91-5% (в зависимости от настроек производительности), в то время как для распознавания человеком этот показатель составляет 5.83%, при работе Mozilla Voice (Deep Speech) - 5-6.5%, Google Speech - 6.64%, wit.ai - 7.94%, Bing Speech - 11.73%, Apple Dictation - 14.24%.