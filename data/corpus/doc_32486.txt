Увидел свет дистрибутив Red Hat Enterprise Linux 6.2

Компания Red Hat анонсировала выход дистрибутива Red Hat Enterprise Linux 6.2, в котором представлено исправление ошибок, реализация поддержки нового оборудования и добавление новых возможностей, при сохранении полной совместимости с программным окружением ветки RHEL 6.x. RHEL 6.2 поставляется в следующих вариантах: Red Hat Enterprise Linux Client 6 для архитектур x86 и AMD64/Intel 64 Red Hat Enterprise Linux High Performance Compute Node 6 для архитектуры AMD64/Intel 64 Red Hat Enterprise Linux Server для архитектур x86, AMD64/Intel 64, IBM System z и IBM POWER; Red Hat Enterprise Linux Workstation для архитектур x86 и AMD64/Intel 64. Ключевые новшества Red Hat Enterprise Linux 6.2: Производительность и масштабируемость Оптимизации производительности и масштабируемости на уровне ядра в планировщике процессов, сетевой подсистеме, системах ввода/вывода и в реализациях технологий виртуализации. Увеличение скорости создания файловых систем Ext4; Увеличение масштабируемости, оптимизация производительности и сокращение времени отклика для некоторых применений файловой системы XFS, связанных с интенсивной обработкой мета-данных (например, множество мелких файлов в директории); Улучшение средств по управлению ресурсами CPU с использованием Cgroups; Поддержка "Transparent Huge Рages", техники увеличения базового размера адресуемых страниц памяти, приводящей к увеличению производительности активно использующих память приложений (например, Huge Рages эффективны при использовании систем виртуализации и СУБД); Обеспечение высокой доступности (High Availability) В пакет дополнений High Availability добавлена поддержка работы Red Hat Enterprise Linux 6 в качестве гостевых систем под управлением VMware с возможностью организации совместного доступа к хранилищам на базе файловой системы GFS2; Полная поддержка протокола Unicast UDP, позволяющего упростить развертывание кластера и обеспечить передачу управляющей информации внутри кластера без необходимости реконфигурации коммутаторов; Поддержка кластерных конфигураций Samba (Clustered Samba), работающих поверх файловой системы GFS2. CTDB распределяет мета-данные Samba-разделов на несколько хостов в кластере, что позволяет обеспечить автоматическое восстановление в случае сбоя одного из узлов; Системы хранения Поддержка WWN (World Wide Name) и WWID (World Wide Identifier) для упрощения идентификации устройств хранения в процессе установки для пользователей, использующих SAN (Storage Area Networks) и другие расширенные сетевые топологии; Поддержка Infiniband объявлена готовой для промышленной эксплуатации. Red Hat Enterprise Linux может быть использован как iSCSI initiator и сервер хранения; Поддержка MD RAID в пространстве пользователя: утилиты mdadm и mdmon теперь поддерживают автоматическое перестроение RAID-массива, миграцию RAID, RAID 5 и руминг дисков SAS-SATA; Добавлена специализированная псевдо-файловая система "pstore", предназначенная для организации доступа к присутствующим на некоторых платформах хранилищам, позволяющим сохранить отладочную информацию о причине краха между перезагрузками; Экспериментальная поддержка LVM RAID, позволяющая создавать, просматривать, переименовывать и удалять логические RAID-разделы; Поддержка Parallel NFS (pNFS), позволяет организовать высокоскоростной обмен данными между машинами сети за счет возможности распараллеливания обращения к данным на нескольких хранилищах, а также разделения передачи потоков данных и мета-данных; Поддержка асинхронной записи для файловой системы CIFS, что в некоторых ситуациях может привести к повышению производительности на 200% за счет организации записи в параллельном режиме. Кроме того, в CIFS добавлена поддержка аутентификации NTLMSSP; Виртуализация Поддержка в KVM совмещения квантов времени между виртуальными CPU, когда один виртуальный CPU может отдать остававшуюся часть кванта времени другому виртуальному CPU до момента наступления стадии освобождения CPU. Функция позволяет решить некоторые проблемы с блокировками и обеспечить более стабильную производительность гостевым системам с несколькими виртуальными CPU; Несколько оптимизаций производительности в сетевых паравиртуальных драйверах KVM: увеличение скорости передачи небольших сообщений (менее 4 Кб); обеспечение десятигигабитных скоростей для KVM-драйверов без проброса PCI-карт (за счет использования техники zero-copy в macvtap/vhost); оптимизация вычисления контрольных сумм для UDP в драйвере virtio-net; увеличения производительности ввода/вывода, когда хост медленнее гостевой системы; Реализация пакета libvirt-snmp, позволяющего отправлять информацию о событиях для мониторинга KVM в виде SNMP трапов; Улучшение средств KVM для отладки и выявления причин крахов гостевых систем; Возможность контроля загрузки гостевых систем на стадии запуска BIOS и начальной фазе загрузки ядра (добавлен драйвер sgabios и внесены изменения в qemu-kvm); Поддержка технологии Live Snapshot для автоматического резервного копирования состояния дисковых образов для работающих гостевых систем. Live Snapshot позволяет прозрачно скопировать в формате qcow2 содержимое виртуального диска в целостном виде (состояние резервной копии аналогично выключению питания и требует запуска fsck), без остановки работы виртуальной машины; В qemu-kvm реализована поддержка эмуляции USB 2.0; В Xen добавлена поддержка "Memory ballooning", что позволяет гипервизору виртуализированной гостевой операционной системы динамически ограничивать объём доступной оперативной памяти и передавать неиспользуемую память окружениям, нуждающимся в памяти. При нехватке памяти физическая память возвращается. Максимальный размер памяти для domU PV окружений Xen на платформе x86_64 увеличен до 128 Гб; До версии 0.8.1 обновлена реализация протокола Spice. В новой версии добавлена возможность изменения громкости, поддержка асинхронных операций записи, реализована поддержка связанных со спящим режимом (suspend, S3) операций ввода/вывода; Экспериментальная поддержка легковесных изолированных контейнеров (Linux Сontainer), позволяющих изолировать отдельное приложение без задействования полноценной виртуализации. Ограничения доступа задаются через cgroup и namespaces. В настоящее время поддерживаются операции по созданию контейнера, изменению параметров и удалению через libvirt API или virt-manager GUI. Управление идентификацией Средства централизованного управления идентификацией для более гибкого управления пользователями, ролями, политиками и сервисами аутентификации; Новые возможности для унификации присвоения идентификаторов пользователей и групп, билетов Kerberos, назначения имен в DNS и определения системных политик через единый сервис; Поддержка смарт-карт с интерфейсом PIV (Personal Identity Verification); Сетевые возможности Поддержка технологии XPS (Transmit Packet Steering), позволяющей повысить на 20-30% пропускную способность передачи сетевых пакетов для адаптеров, поддерживающих несколько очередей пакетов; Поддержка IPSet, позволяющего повысить эффективность работы пакетного фильтра с большими списками IP-адресов и подсетей. Подробнее об особенностях ipset можно прочитать здесь; Поддержка режима множественной адресации (Multihome) для протокола SCTP, при котором передача данных может осуществляться одновременно с нескольких IP-адресов в рамках одной сессии; Расширение числа точек трассировки для определения причины отбрасывания UDP-пакетов; С 4 до 15 Кб увеличен размер по умолчанию для начального принимающего окна TCP, т.е. размер буфера увеличен почти в 4 раза. В соответствии с RFC 5681 размер окна контроля перегрузки TCP установлен в 10; Поддержка системного вызова recvmmsg(), позволяющего организовать получение в рамках одного системного вызова сразу нескольких сообщений, которые ранее потребовали бы отдельных вызовов recvmsg(). Технология значительно повышает эффективность работы приложений передающих большие объемы данных или оперирующих пакетами небольшого размера; В IPv6 добавлена поддержка GSO (Generic Segmentation Offload), что позволит увеличить производительность передачи данных между хостом и гостевыми системами. Оборудование Значительное обновление драйверов и подсистем, связанных с поддержкой оборудования. Из основного ядра портированы драйверы для сетевых адаптеров, устройств хранения, графических карт и другого оборудования; Поддержка target-режима Fiber Channel over Ethernet (FCoE); Поддержка UV2 Hub; Поддержка запуска систем UEFI в режиме виртуальной адресации (ранее поддерживалась только физическая адресация); Портирован драйвер MXM (Mobile PCI Express Module), отвечающий за управление переключением GPU на платформах NVIDIA; Добавлена поддержка OProfile для новых процессоров Intel;